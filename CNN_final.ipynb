{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UwaU2oQTVb-",
        "outputId": "8c9e07b9-c437-4ae0-e98e-d9b513cdff48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 189, Train: 151, Test: 38\n",
            "Epoch 1/10 - Loss: 31.854653 - Time: 48.53s\n",
            "Epoch 2/10 - Loss: 4.351855 - Time: 44.44s\n",
            "Epoch 3/10 - Loss: 2.729854 - Time: 43.99s\n",
            "Epoch 4/10 - Loss: 1.198484 - Time: 44.65s\n",
            "Epoch 5/10 - Loss: 1.090384 - Time: 44.48s\n",
            "Epoch 6/10 - Loss: 1.063669 - Time: 44.02s\n",
            "Epoch 7/10 - Loss: 0.963861 - Time: 44.48s\n",
            "Epoch 8/10 - Loss: 0.962477 - Time: 43.78s\n",
            "Epoch 9/10 - Loss: 0.890112 - Time: 44.39s\n",
            "Epoch 10/10 - Loss: 0.933416 - Time: 45.12s\n",
            "Total Loss: 0.02\n",
            "Accuracy: 98.35 %\n",
            "Total Training Time: 447.88 seconds\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "\n",
        "# =====================\n",
        "# 1️⃣ Load Encoded Data (Modified for CNN)\n",
        "# =====================\n",
        "def load_encoded_data(one_hot_csv, train_ratio=0.8, input_size=7098):\n",
        "    one_hot_data = pd.read_csv(one_hot_csv, header=None).values.astype(np.float32)\n",
        "    num_samples = one_hot_data.shape[0]\n",
        "\n",
        "    # Reshape for CNN: (batch, channels, length)\n",
        "    one_hot_data = one_hot_data.reshape((num_samples, 1, input_size))  # Adding channel dimension\n",
        "\n",
        "    X = torch.tensor(one_hot_data, dtype=torch.float32)\n",
        "    dataset = TensorDataset(X, X)\n",
        "\n",
        "    train_size = max(1, int(train_ratio * len(dataset)))\n",
        "    test_size = len(dataset) - train_size\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    print(f\"Total samples: {len(dataset)}, Train: {train_size}, Test: {test_size}\")\n",
        "    return train_dataset, test_dataset\n",
        "\n",
        "# =====================\n",
        "# 2️⃣ CNN Autoencoder (Fixed Dimensions)\n",
        "# =====================\n",
        "class CNNEncoder(nn.Module):\n",
        "    def __init__(self, input_length=7098, latent_dim=200):\n",
        "        super(CNNEncoder, self).__init__()\n",
        "\n",
        "        # Calculate the output size after convolutions\n",
        "        self.conv1 = nn.Conv1d(1, 64, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv3 = nn.Conv1d(128, 256, kernel_size=5, stride=2, padding=2)\n",
        "        self.conv4 = nn.Conv1d(256, 512, kernel_size=5, stride=2, padding=2)\n",
        "\n",
        "        # Calculate the flattened size\n",
        "        self.flattened_size = self._get_conv_output(input_length)\n",
        "        self.fc = nn.Linear(self.flattened_size, latent_dim)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(256)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "\n",
        "    def _get_conv_output(self, length):\n",
        "        # Helper function to calculate the output size after convolutions\n",
        "        with torch.no_grad():\n",
        "            dummy = torch.zeros(1, 1, length)\n",
        "            dummy = self.conv1(dummy)\n",
        "            dummy = self.conv2(dummy)\n",
        "            dummy = self.conv3(dummy)\n",
        "            dummy = self.conv4(dummy)\n",
        "            return dummy.numel()  # Total elements after flattening\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.relu(self.bn4(self.conv4(x)))\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "class CNNDecoder(nn.Module):\n",
        "    def __init__(self, output_length=7098, latent_dim=200):\n",
        "        super(CNNDecoder, self).__init__()\n",
        "        self.output_length = output_length\n",
        "\n",
        "        # Calculate the unflattened size (must match encoder's last conv output)\n",
        "        self.conv_output_size = 512 * ((output_length // 16) + 1)  # Adjusted calculation\n",
        "\n",
        "        self.fc = nn.Linear(latent_dim, self.conv_output_size)\n",
        "\n",
        "        self.deconv1 = nn.ConvTranspose1d(512, 256, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.deconv2 = nn.ConvTranspose1d(256, 128, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.deconv3 = nn.ConvTranspose1d(128, 64, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "        self.deconv4 = nn.ConvTranspose1d(64, 1, kernel_size=5, stride=2, padding=2, output_padding=1)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.bn1 = nn.BatchNorm1d(256)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc(x)\n",
        "        x = x.view(x.size(0), 512, -1)  # Reshape to match encoder's last conv output\n",
        "\n",
        "        x = self.relu(self.bn1(self.deconv1(x)))\n",
        "        x = self.relu(self.bn2(self.deconv2(x)))\n",
        "        x = self.relu(self.bn3(self.deconv3(x)))\n",
        "        x = self.deconv4(x)\n",
        "\n",
        "        # Ensure output has the correct length\n",
        "        if x.size(2) > self.output_length:\n",
        "            x = x[:, :, :self.output_length]\n",
        "        elif x.size(2) < self.output_length:\n",
        "            padding = torch.zeros(x.size(0), 1, self.output_length - x.size(2), device=x.device)\n",
        "            x = torch.cat([x, padding], dim=2)\n",
        "        return x\n",
        "\n",
        "class CNNAutoencoder(nn.Module):\n",
        "    def __init__(self, input_length=7098, latent_dim=200):\n",
        "        super(CNNAutoencoder, self).__init__()\n",
        "        self.encoder = CNNEncoder(input_length, latent_dim)\n",
        "        self.decoder = CNNDecoder(input_length, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        reconstructed = self.decoder(encoded)\n",
        "        return reconstructed\n",
        "\n",
        "# =====================\n",
        "# 3️⃣ Training (Same as before)\n",
        "# =====================\n",
        "def train_model(model, train_dataset, epochs=10, batch_size=4, learning_rate=0.15):\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9, weight_decay=1e-5)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        epoch_start_time = time.time()\n",
        "        total_loss = 0.0\n",
        "        for X, _ in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X)\n",
        "            loss = criterion(outputs, X)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss:.6f} - Time: {time.time() - epoch_start_time:.2f}s\")\n",
        "\n",
        "    end_time = time.time()\n",
        "    accuracy = (1-loss)*100\n",
        "    print(f\"Total Loss: {loss:.2f}\")\n",
        "    print(f\"Accuracy: {accuracy:.2f} %\")\n",
        "    print(f\"Total Training Time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "# =====================\n",
        "# 4️⃣ Run Training with CNN\n",
        "# =====================\n",
        "one_hot_csv = \"basepaper_encoded.csv\"\n",
        "train_dataset, test_dataset = load_encoded_data(one_hot_csv, input_size=7098)\n",
        "model = CNNAutoencoder(input_length=7098)\n",
        "\n",
        "train_model(model, train_dataset, epochs=10, batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK17UzvhTm7I",
        "outputId": "f0079401-c996-4b78-f0ce-ea9d3b728826"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "basepaper_encoded.csv  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N8sM3bzKUqAy"
      },
      "execution_count": 1,
      "outputs": []
    }
  ]
}